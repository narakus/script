#!/usr/bin/env python

import re
import urllib
import urllib2
import BeautifulSoup as bs
from sys import argv,exit
from prettytable import PrettyTable

url = 'http://192.168.15.177/'
url_list = []
down_list = []

row = PrettyTable()
row.field_names = ["Name", "Date","Size","Type"]

def split_url(u):
    html = urllib2.urlopen(u)
    soup = bs.BeautifulSoup(html.read())
    for i in soup.findAll('a'):
        if i.contents[0].endswith('/') and not i.contents[0] == "../":
            url_list.append(u + i.contents[0])
            durl = url + i.contents[0]
            split_url(durl)
    return url_list

def print_list(u):
    for line in urllib2.urlopen(u).readlines():
        try:
            r = re.search(r'<a href=.*>(.*)</a>\s+(\d+-.*-\d+\s\d+:\d+)\s+(\d+)\r\n',line)

            if r.groups():
                name  = r.group(1)
                mydate = r.group(2)
                size = int(r.group(3))
                if size > 1048576:
                        mysize = str(size/1024/1024) + 'M'
                elif size < 1024:
                        mysize = str(size) + 'B'
                else:
                        mysize = str(size/1014) + 'KB'

                if name.endswith('gz') or name.endswith('zip'):
                        mytype = 'binary'
                elif name.endswith('sh') or name.endswith('py'):
                        mytype = 'script'
                else:
                        mytype = 'other'

                row.add_row([name,mydate,mysize,mytype])
                down_list.append(u + name)

        except: pass

    return down_list

if __name__ == '__main__':
    split_url(url)
    url_list.append(url)
    for item in url_list:
        print_list(item)
    
    if len(argv) == 1:
            print row

    for i in range(1,len(argv)):
        for item in down_list:
            if argv[i] in item:
                urllib.urlretrieve(item,item.rstrip('\n').split('/')[-1])
